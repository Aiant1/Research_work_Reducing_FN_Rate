{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model \"model_whole.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow import keras \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "import glob\n",
    "from PIL import Image, ImageFile\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import tensorflow.contrib.slim as slim\n",
    "# import tensorflow.contrib.slim.nets as nets\n",
    "import h5py\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "# !pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"/nas/home/ellak-1000013/share/to_joul_2020-12-07/models-v02a3/model_whole.h5\"\n",
    "loaded =load_model(\"/nas/home/ellak-1000013/share/to_joul_2020-12-07/models-v02a3/model_whole.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = keras.models.Model(inputs=loaded.input, outputs=loaded.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(loaded)\n",
    "# model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "# model.add(keras.layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"/home/antika/nipgboardprojects/nipgboardprojects/nipg-board-v3/skin_antika/train_test_valid/train_test_valid/\"\n",
    "# \" #This is the ABSOLUTE path to the database directory. Tensorboard and NIPGBoard\n",
    " \n",
    "    #should be executed on this directory.\n",
    "image_folder= \"test\" #Within the logdir, this folder contains the images to be parsed.\n",
    "\n",
    "embedding_folder = \"embedding\" #Within the logdir, this folder will contain the embedding data.\n",
    "\n",
    "video_folder = \"video\" #Within the logdir, this folder will contain the videos for the video player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def formatImage(im):\n",
    "    bgr = im.split()\n",
    "    im = Image.merge(\"RGB\", (bgr[2], bgr[1], bgr[0]))\n",
    "    im = im.resize((256, 256), Image.ANTIALIAS)\n",
    "    return np.asarray(im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_array(image_folder):\n",
    "    png_files = glob.glob(os.path.join(logdir, image_folder, '*png'))\n",
    "    jpg_files = glob.glob(os.path.join(logdir, image_folder, '*jpg'))\n",
    "    sprite = os.path.join(logdir, image_folder, 'sprite.png')\n",
    "    labels=[]\n",
    "    if sprite in png_files:\n",
    "        png_files.remove(sprite)\n",
    "    image_files = sorted(png_files + jpg_files)\n",
    "    X = np.zeros(shape=(len(image_files), 256, 256, 3), dtype=np.uint8)\n",
    "    for i in range(len(image_files)):\n",
    "        X[i] = formatImage(Image.open(image_files[i]))\n",
    "        labels.append(os.path.basename(image_files[i]).split('_')[0])\n",
    "    X = X.astype('float32')\n",
    "    return X,labels,image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,x_train_label,image_files_train=get_array(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,x_test_label,image_files_test=get_array(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid,x_valid_label,image_file_valid=get_array(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# x_train_label = label_encoder.fit_transform(x_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_label = pd.get_dummies(x_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_valid_label = pd.get_dummies(x_valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_valid_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=\"adam\",\n",
    "#               loss=keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train,x_train_label,epochs=10,verbose=2,validation_data=(X_valid,x_valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.Model(inputs=model.input, outputs=model.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output = loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.     , 161.24004,  82.1569 , ..., 115.65387,   0.     ,\n",
       "       210.59253], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sprite_image(img_paths, size):\n",
    "    n_images = len(img_paths)\n",
    "    img_h = size\n",
    "    img_w = size\n",
    "    n_plots = int(np.ceil(np.sqrt(n_images)))\n",
    "    \n",
    "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots, 3))\n",
    "    \n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < n_images:\n",
    "                img = cv2.imread(img_paths[this_filter])\n",
    "                img = cv2.resize(img, (size,size))\n",
    "\n",
    "                spriteimage[i * img_h:(i + 1) * img_h,\n",
    "                  j * img_w:(j + 1) * img_w] = img\n",
    "    \n",
    "    return spriteimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeProjector(logdir, embedding_data, embedding_name, embedding_folder, image_paths, labels=None):\n",
    "    \"\"\"data: np array\"\"\"\n",
    "    sprite_size = 28\n",
    "    sprite_path = os.path.join(logdir, embedding_folder, 'sprite.png')\n",
    "    meta_path = os.path.join(logdir,embedding_folder,'metadata.tsv')\n",
    "    checkpoint_path = os.path.join(logdir, embedding_folder, embedding_name+'.ckpt')\n",
    "\n",
    "    embedding_var = tf.Variable(embedding_data, name=embedding_name)\n",
    "    sess = tf.Session()\n",
    "    sess.run(embedding_var.initializer)\n",
    "    summary_writer = tf.summary.FileWriter(os.path.join(logdir,embedding_folder))\n",
    "    summary_writer.add_graph(sess.graph)\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embedding_var.name\n",
    "\n",
    "    embedding.metadata_path = meta_path\n",
    "    embedding.sprite.image_path = sprite_path\n",
    "    embedding.sprite.single_image_dim.extend([sprite_size, sprite_size])\n",
    "\n",
    "    projector.visualize_embeddings(summary_writer, config)\n",
    "    saver = tf.train.Saver([embedding_var])\n",
    "    saver.save(sess, checkpoint_path, 1)\n",
    "\n",
    "    if not os.path.isfile(sprite_path):\n",
    "        sprite_image = create_sprite_image(image_paths, sprite_size)\n",
    "        cv2.imwrite(sprite_path, sprite_image)\n",
    "\n",
    "    # Create a metadata file if you want to using code similar to this:\n",
    "    if not os.path.isfile(meta_path):\n",
    "        if labels == None:\n",
    "            with open(meta_path,'w') as f:\n",
    "                f.write(\"Index\\tFilename\\t_sync_id\\n\")\n",
    "                for index, img_path in enumerate(image_paths):\n",
    "                    f.write(\"%d\\t%s\\t%d\\n\" % (index, img_path.split('/')[-1].split('\\\\')[-1], index))\n",
    "        else:    \n",
    "            with open(meta_path,'w') as f:\n",
    "                f.write(\"Index\\tLabel\\tFilename\\t_sync_id\\n\")\n",
    "                \n",
    "                for index,(label, img_path) in enumerate(zip(labels, image_paths)):\n",
    "                    f.write(\"%d\\t%s\\t%s\\t%d\\n\" % (index,label, img_path, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeProjector(logdir=logdir,\n",
    "    embedding_data=intermediate_output,\n",
    "    embedding_name='dense_1',        \n",
    "    embedding_folder=embedding_folder,\n",
    "    image_paths=image_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"default\": {\n",
    "        \"embedding_folder\": embedding_folder,\n",
    "        \"name\": \"DENSENET\",\n",
    "        \"image_folder\": image_folder,\n",
    "        \"video_folder\": video_folder\n",
    "    },\n",
    "    \n",
    "    \"training\": {\n",
    "        \"algorithm_path\": \"/home/antika/nipgboardprojects/nipgboardprojects/nipg-board-v3/algorithms\",\n",
    "        \"embedding_folder\": \"densenet\",\n",
    "        \"name\": \"DENSENET+KIRA\",\n",
    "        \"algorithm\": {\n",
    "            \"callable\": \"run\",\n",
    "            \"keyword_arguments\": {\n",
    "                \"epoch\": \"1\"\n",
    "            },\n",
    "            \"arguments\": [],\n",
    "            \"file\": \"densenet\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(logdir, 'cnf.json'), 'w') as fp:\n",
    "    json.dump(config_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugins_dict = {\n",
    "    \"plugins\": [\"executer\", \"selected\", \"image\", \"projector\", \"video\"]\n",
    "}\n",
    "with open(os.path.join(logdir, 'plugins.json'), 'w') as fp:\n",
    "    json.dump(plugins_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(logdir,embedding_folder,'metadata.tsv'), 'wt') as metadata_file:\n",
    "    metadata_file.write('Index\\tLabel\\tFilename\\t_sync_id\\n')\n",
    "    for i in range(len(image_files_test)):\n",
    "        metadata_file.write('%d\\t%s\\t%s\\t%d\\n' % (i, image_files_test[i].split('/')[-1].split('\\\\')[-1].split('_')[0], image_files_test[i].split('/')[-1].split('\\\\')[-1], i))\n",
    "    metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
